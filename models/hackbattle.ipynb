{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":974,"sourceType":"datasetVersion","datasetId":478},{"sourceId":2286,"sourceType":"datasetVersion","datasetId":1275},{"sourceId":2983853,"sourceType":"datasetVersion","datasetId":1828813},{"sourceId":3036086,"sourceType":"datasetVersion","datasetId":1859421},{"sourceId":4832081,"sourceType":"datasetVersion","datasetId":2799910}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-25T10:37:18.295488Z","iopub.execute_input":"2024-09-25T10:37:18.295976Z","iopub.status.idle":"2024-09-25T10:37:19.632198Z","shell.execute_reply.started":"2024-09-25T10:37:18.295932Z","shell.execute_reply":"2024-09-25T10:37:19.630545Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/housing-prices-dataset/Housing.csv\n/kaggle/input/salary-dataset-simple-linear-regression/Salary_dataset.csv\n/kaggle/input/mushroom-classification/mushrooms.csv\n/kaggle/input/titanic/train_and_test2.csv\n/kaggle/input/heart-disease-dataset/heart.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2024-09-25T10:39:49.908135Z","iopub.execute_input":"2024-09-25T10:39:49.909090Z","iopub.status.idle":"2024-09-25T10:39:49.917846Z","shell.execute_reply.started":"2024-09-25T10:39:49.909039Z","shell.execute_reply":"2024-09-25T10:39:49.916390Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Preprocessing function\ndef preprocess_data(df, target_column):\n    # Handle missing values\n    df = df.dropna()\n    \n    # Encode categorical features\n    label_encoders = {}\n    for col in df.select_dtypes(include=['object']).columns:\n        le = LabelEncoder()\n        df[col] = le.fit_transform(df[col])\n        label_encoders[col] = le\n        \n    # Split data into features and labels\n    X = df.drop(target_column, axis=1)\n    y = df[target_column]\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n\n    return X_train, X_test, y_train, y_test\n\n# Function to evaluate models\ndef evaluate_model(X_train, X_test, y_train, y_test):\n    models = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"Decision Tree\": DecisionTreeClassifier(),\n    \"Random Forest\": RandomForestClassifier(),\n    \"SVM\": SVC(),\n    \"KNN\": KNeighborsClassifier(),\n    \"Gradient Boosting\": GradientBoostingClassifier(),\n    \"XGBoost\": xgb.XGBClassifier(),\n    \"AdaBoost\": AdaBoostClassifier(),\n    \"Naive Bayes\": GaussianNB(),\n    \"MLP Neural Network\": MLPClassifier()\n    }\n    \n    for name, model in models.items():\n        start_time = time.time()\n        print(f\"Training {name}...\")\n        model = model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        time_consumed = time.time() - start_time\n        print(f\"{name} Accuracy: {np.round(accuracy,2)} Time: {time_consumed}\")\n\n# Run all classifiers\ndef run_all_classifiers(df, target_column):\n    X_train, X_test, y_train, y_test = preprocess_data(df, target_column)\n    \n    evaluate_model(X_train, X_test, y_train, y_test)\n    \n\n# Example usage with a dataset\nif __name__ == \"__main__\":\n    # Load your dataset here\n    df = pd.read_csv(\"/kaggle/input/mushroom-classification/mushrooms.csv\")\n    target_column = 'class'  # Change this to your dataset's target column\n    \n    # Run all classifiers on the dataset\n    run_all_classifiers(df, target_column)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T10:39:50.353130Z","iopub.execute_input":"2024-09-25T10:39:50.353586Z","iopub.status.idle":"2024-09-25T10:39:56.136007Z","shell.execute_reply.started":"2024-09-25T10:39:50.353545Z","shell.execute_reply":"2024-09-25T10:39:56.134415Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Training Logistic Regression...\nLogistic Regression Accuracy: 0.95 Time: 0.09845662117004395\nTraining Decision Tree...\nDecision Tree Accuracy: 1.0 Time: 0.022804737091064453\nTraining Random Forest...\nRandom Forest Accuracy: 1.0 Time: 0.5513401031494141\nTraining SVM...\nSVM Accuracy: 1.0 Time: 0.22307944297790527\nTraining KNN...\nKNN Accuracy: 1.0 Time: 0.19657158851623535\nTraining Gradient Boosting...\nGradient Boosting Accuracy: 1.0 Time: 0.6859261989593506\nTraining XGBoost...\nXGBoost Accuracy: 1.0 Time: 0.14061450958251953\nTraining AdaBoost...\nAdaBoost Accuracy: 1.0 Time: 0.35639023780822754\nTraining Naive Bayes...\nNaive Bayes Accuracy: 0.92 Time: 0.007741451263427734\nTraining MLP Neural Network...\nMLP Neural Network Accuracy: 1.0 Time: 3.3321897983551025\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/mushroom-classification/mushrooms.csv\")\ndf\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T10:39:59.786147Z","iopub.execute_input":"2024-09-25T10:39:59.786652Z","iopub.status.idle":"2024-09-25T10:39:59.851068Z","shell.execute_reply.started":"2024-09-25T10:39:59.786606Z","shell.execute_reply":"2024-09-25T10:39:59.849766Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"     class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n0        p         x           s         n       t    p               f   \n1        e         x           s         y       t    a               f   \n2        e         b           s         w       t    l               f   \n3        p         x           y         w       t    p               f   \n4        e         x           s         g       f    n               f   \n...    ...       ...         ...       ...     ...  ...             ...   \n8119     e         k           s         n       f    n               a   \n8120     e         x           s         n       f    n               a   \n8121     e         f           s         n       f    n               a   \n8122     p         k           y         n       f    y               f   \n8123     e         x           s         n       f    n               a   \n\n     gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n0               c         n          k  ...                        s   \n1               c         b          k  ...                        s   \n2               c         b          n  ...                        s   \n3               c         n          n  ...                        s   \n4               w         b          k  ...                        s   \n...           ...       ...        ...  ...                      ...   \n8119            c         b          y  ...                        s   \n8120            c         b          y  ...                        s   \n8121            c         b          n  ...                        s   \n8122            c         n          b  ...                        k   \n8123            c         b          y  ...                        s   \n\n     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n0                         w                      w         p          w   \n1                         w                      w         p          w   \n2                         w                      w         p          w   \n3                         w                      w         p          w   \n4                         w                      w         p          w   \n...                     ...                    ...       ...        ...   \n8119                      o                      o         p          o   \n8120                      o                      o         p          n   \n8121                      o                      o         p          o   \n8122                      w                      w         p          w   \n8123                      o                      o         p          o   \n\n     ring-number ring-type spore-print-color population habitat  \n0              o         p                 k          s       u  \n1              o         p                 n          n       g  \n2              o         p                 n          n       m  \n3              o         p                 k          s       u  \n4              o         e                 n          a       g  \n...          ...       ...               ...        ...     ...  \n8119           o         p                 b          c       l  \n8120           o         p                 b          v       l  \n8121           o         p                 b          c       l  \n8122           o         e                 w          v       l  \n8123           o         p                 o          c       l  \n\n[8124 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>cap-shape</th>\n      <th>cap-surface</th>\n      <th>cap-color</th>\n      <th>bruises</th>\n      <th>odor</th>\n      <th>gill-attachment</th>\n      <th>gill-spacing</th>\n      <th>gill-size</th>\n      <th>gill-color</th>\n      <th>...</th>\n      <th>stalk-surface-below-ring</th>\n      <th>stalk-color-above-ring</th>\n      <th>stalk-color-below-ring</th>\n      <th>veil-type</th>\n      <th>veil-color</th>\n      <th>ring-number</th>\n      <th>ring-type</th>\n      <th>spore-print-color</th>\n      <th>population</th>\n      <th>habitat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>p</td>\n      <td>x</td>\n      <td>s</td>\n      <td>n</td>\n      <td>t</td>\n      <td>p</td>\n      <td>f</td>\n      <td>c</td>\n      <td>n</td>\n      <td>k</td>\n      <td>...</td>\n      <td>s</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>k</td>\n      <td>s</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e</td>\n      <td>x</td>\n      <td>s</td>\n      <td>y</td>\n      <td>t</td>\n      <td>a</td>\n      <td>f</td>\n      <td>c</td>\n      <td>b</td>\n      <td>k</td>\n      <td>...</td>\n      <td>s</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>n</td>\n      <td>n</td>\n      <td>g</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e</td>\n      <td>b</td>\n      <td>s</td>\n      <td>w</td>\n      <td>t</td>\n      <td>l</td>\n      <td>f</td>\n      <td>c</td>\n      <td>b</td>\n      <td>n</td>\n      <td>...</td>\n      <td>s</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>n</td>\n      <td>n</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>p</td>\n      <td>x</td>\n      <td>y</td>\n      <td>w</td>\n      <td>t</td>\n      <td>p</td>\n      <td>f</td>\n      <td>c</td>\n      <td>n</td>\n      <td>n</td>\n      <td>...</td>\n      <td>s</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>k</td>\n      <td>s</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e</td>\n      <td>x</td>\n      <td>s</td>\n      <td>g</td>\n      <td>f</td>\n      <td>n</td>\n      <td>f</td>\n      <td>w</td>\n      <td>b</td>\n      <td>k</td>\n      <td>...</td>\n      <td>s</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>e</td>\n      <td>n</td>\n      <td>a</td>\n      <td>g</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8119</th>\n      <td>e</td>\n      <td>k</td>\n      <td>s</td>\n      <td>n</td>\n      <td>f</td>\n      <td>n</td>\n      <td>a</td>\n      <td>c</td>\n      <td>b</td>\n      <td>y</td>\n      <td>...</td>\n      <td>s</td>\n      <td>o</td>\n      <td>o</td>\n      <td>p</td>\n      <td>o</td>\n      <td>o</td>\n      <td>p</td>\n      <td>b</td>\n      <td>c</td>\n      <td>l</td>\n    </tr>\n    <tr>\n      <th>8120</th>\n      <td>e</td>\n      <td>x</td>\n      <td>s</td>\n      <td>n</td>\n      <td>f</td>\n      <td>n</td>\n      <td>a</td>\n      <td>c</td>\n      <td>b</td>\n      <td>y</td>\n      <td>...</td>\n      <td>s</td>\n      <td>o</td>\n      <td>o</td>\n      <td>p</td>\n      <td>n</td>\n      <td>o</td>\n      <td>p</td>\n      <td>b</td>\n      <td>v</td>\n      <td>l</td>\n    </tr>\n    <tr>\n      <th>8121</th>\n      <td>e</td>\n      <td>f</td>\n      <td>s</td>\n      <td>n</td>\n      <td>f</td>\n      <td>n</td>\n      <td>a</td>\n      <td>c</td>\n      <td>b</td>\n      <td>n</td>\n      <td>...</td>\n      <td>s</td>\n      <td>o</td>\n      <td>o</td>\n      <td>p</td>\n      <td>o</td>\n      <td>o</td>\n      <td>p</td>\n      <td>b</td>\n      <td>c</td>\n      <td>l</td>\n    </tr>\n    <tr>\n      <th>8122</th>\n      <td>p</td>\n      <td>k</td>\n      <td>y</td>\n      <td>n</td>\n      <td>f</td>\n      <td>y</td>\n      <td>f</td>\n      <td>c</td>\n      <td>n</td>\n      <td>b</td>\n      <td>...</td>\n      <td>k</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>e</td>\n      <td>w</td>\n      <td>v</td>\n      <td>l</td>\n    </tr>\n    <tr>\n      <th>8123</th>\n      <td>e</td>\n      <td>x</td>\n      <td>s</td>\n      <td>n</td>\n      <td>f</td>\n      <td>n</td>\n      <td>a</td>\n      <td>c</td>\n      <td>b</td>\n      <td>y</td>\n      <td>...</td>\n      <td>s</td>\n      <td>o</td>\n      <td>o</td>\n      <td>p</td>\n      <td>o</td>\n      <td>o</td>\n      <td>p</td>\n      <td>o</td>\n      <td>c</td>\n      <td>l</td>\n    </tr>\n  </tbody>\n</table>\n<p>8124 rows × 23 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\n\n# Preprocessing function for regression problems\ndef preprocess_data(df, target_column):\n    # Handle missing values\n    df = df.dropna()\n    \n    # Encode categorical features\n    label_encoders = {}\n    for col in df.select_dtypes(include=['object']).columns:\n        le = LabelEncoder()\n        df[col] = le.fit_transform(df[col])\n        label_encoders[col] = le\n        \n    # Split data into features and labels\n    X = df.drop(target_column, axis=1)\n    y = df[target_column]\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    # Scale the features\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n\n    return X_train, X_test, y_train, y_test\n\n# Function to evaluate regression models\ndef evaluate_model(X_train, X_test, y_train, y_test):\n    models = {\n        \"Linear Regression\": LinearRegression(),\n        \"Decision Tree\": DecisionTreeRegressor(),\n        \"Random Forest\": RandomForestRegressor(),\n        \"SVM\": SVR(),\n        \"KNN\": KNeighborsRegressor(),\n        \"Gradient Boosting\": GradientBoostingRegressor(),\n        \"XGBoost\": xgb.XGBRegressor(),\n        \"AdaBoost\": AdaBoostRegressor(),\n        \"MLP Neural Network\": MLPRegressor()\n    }\n    \n    for name, model in models.items():\n        start_time = time.time()\n        print(f\"Training {name}...\")\n        model = model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        mse = mean_squared_error(y_test, y_pred)\n        time_consumed = time.time() - start_time\n        print(f\"{name} MSE: {np.round(mse, 2)} Time: {time_consumed}\")\n\n# Run all regression models\ndef run_all_regressors(df, target_column):\n    X_train, X_test, y_train, y_test = preprocess_data(df, target_column)\n    \n    evaluate_model(X_train, X_test, y_train, y_test)\n\n# Example usage with a dataset\nif __name__ == \"__main__\":\n    # Load your dataset here\n    df = pd.read_csv(\"/kaggle/input/housing-prices-dataset/Housing.csv\")\n    target_column = 'price'  # Change this to your dataset's target column\n    \n    # Run all regressors on the dataset\n    run_all_regressors(df, target_column)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T10:40:00.859684Z","iopub.execute_input":"2024-09-25T10:40:00.860160Z","iopub.status.idle":"2024-09-25T10:40:02.424913Z","shell.execute_reply.started":"2024-09-25T10:40:00.860118Z","shell.execute_reply":"2024-09-25T10:40:02.423692Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Training Linear Regression...\nLinear Regression MSE: 1771751116594.04 Time: 0.01517176628112793\nTraining Decision Tree...\nDecision Tree MSE: 3218138497706.42 Time: 0.0027976036071777344\nTraining Random Forest...\nRandom Forest MSE: 1915983457562.67 Time: 0.3173482418060303\nTraining SVM...\nSVM MSE: 5567937467895.9 Time: 0.015606164932250977\nTraining KNN...\nKNN MSE: 2106456221466.06 Time: 0.0031883716583251953\nTraining Gradient Boosting...\nGradient Boosting MSE: 1696387965656.32 Time: 0.09444212913513184\nTraining XGBoost...\nXGBoost MSE: 2032404618961.44 Time: 0.06597089767456055\nTraining AdaBoost...\nAdaBoost MSE: 2335249620161.54 Time: 0.12786483764648438\nTraining MLP Neural Network...\nMLP Neural Network MSE: 30128043642636.24 Time: 0.8714537620544434\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/housing-prices-dataset/Housing.csv\")\ndf","metadata":{"execution":{"iopub.status.busy":"2024-09-25T10:40:06.431529Z","iopub.execute_input":"2024-09-25T10:40:06.431992Z","iopub.status.idle":"2024-09-25T10:40:06.459035Z","shell.execute_reply.started":"2024-09-25T10:40:06.431950Z","shell.execute_reply":"2024-09-25T10:40:06.457662Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"        price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n0    13300000  7420         4          2        3      yes        no       no   \n1    12250000  8960         4          4        4      yes        no       no   \n2    12250000  9960         3          2        2      yes        no      yes   \n3    12215000  7500         4          2        2      yes        no      yes   \n4    11410000  7420         4          1        2      yes       yes      yes   \n..        ...   ...       ...        ...      ...      ...       ...      ...   \n540   1820000  3000         2          1        1      yes        no      yes   \n541   1767150  2400         3          1        1       no        no       no   \n542   1750000  3620         2          1        1      yes        no       no   \n543   1750000  2910         3          1        1       no        no       no   \n544   1750000  3850         3          1        2      yes        no       no   \n\n    hotwaterheating airconditioning  parking prefarea furnishingstatus  \n0                no             yes        2      yes        furnished  \n1                no             yes        3       no        furnished  \n2                no              no        2      yes   semi-furnished  \n3                no             yes        3      yes        furnished  \n4                no             yes        2       no        furnished  \n..              ...             ...      ...      ...              ...  \n540              no              no        2       no      unfurnished  \n541              no              no        0       no   semi-furnished  \n542              no              no        0       no      unfurnished  \n543              no              no        0       no        furnished  \n544              no              no        0       no      unfurnished  \n\n[545 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>area</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>stories</th>\n      <th>mainroad</th>\n      <th>guestroom</th>\n      <th>basement</th>\n      <th>hotwaterheating</th>\n      <th>airconditioning</th>\n      <th>parking</th>\n      <th>prefarea</th>\n      <th>furnishingstatus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13300000</td>\n      <td>7420</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>2</td>\n      <td>yes</td>\n      <td>furnished</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12250000</td>\n      <td>8960</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>3</td>\n      <td>no</td>\n      <td>furnished</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12250000</td>\n      <td>9960</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>no</td>\n      <td>2</td>\n      <td>yes</td>\n      <td>semi-furnished</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12215000</td>\n      <td>7500</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>3</td>\n      <td>yes</td>\n      <td>furnished</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11410000</td>\n      <td>7420</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>2</td>\n      <td>no</td>\n      <td>furnished</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>540</th>\n      <td>1820000</td>\n      <td>3000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>no</td>\n      <td>2</td>\n      <td>no</td>\n      <td>unfurnished</td>\n    </tr>\n    <tr>\n      <th>541</th>\n      <td>1767150</td>\n      <td>2400</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>0</td>\n      <td>no</td>\n      <td>semi-furnished</td>\n    </tr>\n    <tr>\n      <th>542</th>\n      <td>1750000</td>\n      <td>3620</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>0</td>\n      <td>no</td>\n      <td>unfurnished</td>\n    </tr>\n    <tr>\n      <th>543</th>\n      <td>1750000</td>\n      <td>2910</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>0</td>\n      <td>no</td>\n      <td>furnished</td>\n    </tr>\n    <tr>\n      <th>544</th>\n      <td>1750000</td>\n      <td>3850</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>0</td>\n      <td>no</td>\n      <td>unfurnished</td>\n    </tr>\n  </tbody>\n</table>\n<p>545 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import shap\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nimport time\nimport xgboost as xgb\n\n# Preprocessing function with SHAP\ndef preprocess_data_with_shap(df, target_column, shap_threshold=0.01):\n    # Handle missing values\n    df = df.dropna()\n    \n    # Encode categorical features\n    label_encoders = {}\n    for col in df.select_dtypes(include=['object']).columns:\n        le = LabelEncoder()\n        df[col] = le.fit_transform(df[col])\n        label_encoders[col] = le\n        \n    # Split data into features and labels\n    X = df.drop(target_column, axis=1)\n    y = df[target_column]\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    # Standardize features\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    # Train a base model (Random Forest)\n    model = RandomForestClassifier()\n    model.fit(X_train, y_train)\n    \n    # Calculate SHAP values\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X_train)\n    \n    # Calculate mean absolute SHAP values for feature importance\n    shap_importance = np.mean(np.abs(shap_values[1]), axis=0)\n    feature_importance = pd.DataFrame({'feature': df.drop(target_column, axis=1).columns, \n                                       'importance': shap_importance})\n    \n    # Remove features with importance less than the threshold\n    important_features = feature_importance[feature_importance['importance'] > shap_threshold]['feature'].values\n    X_train = pd.DataFrame(X_train, columns=df.drop(target_column, axis=1).columns)[important_features]\n    X_test = pd.DataFrame(X_test, columns=df.drop(target_column, axis=1).columns)[important_features]\n    \n    return X_train, X_test, y_train, y_test\n\n# Function to evaluate models\ndef evaluate_model(X_train, X_test, y_train, y_test):\n    models = {\n        \"Logistic Regression\": LogisticRegression(),\n        \"Decision Tree\": DecisionTreeClassifier(),\n        \"Random Forest\": RandomForestClassifier(),\n        \"SVM\": SVC(),\n        \"KNN\": KNeighborsClassifier(),\n        \"Gradient Boosting\": GradientBoostingClassifier(),\n        \"XGBoost\": xgb.XGBClassifier(),\n        \"AdaBoost\": AdaBoostClassifier(),\n        \"Naive Bayes\": GaussianNB(),\n        \"MLP Neural Network\": MLPClassifier()\n    }\n    \n    for name, model in models.items():\n        start_time = time.time()\n        print(f\"Training {name}...\")\n        model = model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        time_consumed = time.time() - start_time\n        print(f\"{name} Accuracy: {np.round(accuracy,2)} Time: {time_consumed}\")\n\n# Run all classifiers\ndef run_all_classifiers(df, target_column):\n    X_train, X_test, y_train, y_test = preprocess_data_with_shap(df, target_column)\n    evaluate_model(X_train, X_test, y_train, y_test)\n\n# Example usage with a dataset\nif __name__ == \"__main__\":\n    # Load your dataset here\n    df = pd.read_csv(\"/kaggle/input/mushroom-classification/mushrooms.csv\")\n    target_column = 'class'  # Change this to your dataset's target column\n    \n    # Run all classifiers on the dataset\n    run_all_classifiers(df, target_column)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T10:40:08.022649Z","iopub.execute_input":"2024-09-25T10:40:08.023583Z","iopub.status.idle":"2024-09-25T10:40:25.230494Z","shell.execute_reply.started":"2024-09-25T10:40:08.023529Z","shell.execute_reply":"2024-09-25T10:40:25.228299Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Training Logistic Regression...\nLogistic Regression Accuracy: 0.94 Time: 0.09117746353149414\nTraining Decision Tree...\nDecision Tree Accuracy: 1.0 Time: 0.02391195297241211\nTraining Random Forest...\nRandom Forest Accuracy: 1.0 Time: 0.5011825561523438\nTraining SVM...\nSVM Accuracy: 1.0 Time: 0.13839125633239746\nTraining KNN...\nKNN Accuracy: 1.0 Time: 0.16980338096618652\nTraining Gradient Boosting...\nGradient Boosting Accuracy: 1.0 Time: 0.5421617031097412\nTraining XGBoost...\nXGBoost Accuracy: 1.0 Time: 0.09757351875305176\nTraining AdaBoost...\nAdaBoost Accuracy: 1.0 Time: 0.3324575424194336\nTraining Naive Bayes...\nNaive Bayes Accuracy: 0.89 Time: 0.008685827255249023\nTraining MLP Neural Network...\nMLP Neural Network Accuracy: 1.0 Time: 3.7704198360443115\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/mushroom-classification/mushrooms.csv\")\ntarget_column = 'class'\nX=preprocess_data_with_shap(df,target_column)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T10:47:03.473315Z","iopub.execute_input":"2024-09-25T10:47:03.474551Z","iopub.status.idle":"2024-09-25T10:47:10.560689Z","shell.execute_reply.started":"2024-09-25T10:47:03.474490Z","shell.execute_reply":"2024-09-25T10:47:10.559354Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-25T10:47:10.563161Z","iopub.execute_input":"2024-09-25T10:47:10.563577Z","iopub.status.idle":"2024-09-25T10:47:10.589760Z","shell.execute_reply.started":"2024-09-25T10:47:10.563533Z","shell.execute_reply":"2024-09-25T10:47:10.588434Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"       bruises      odor  gill-spacing  gill-size  gill-color  stalk-shape  \\\n0    -0.842237  1.357976     -0.438473   1.498210   -1.354131     0.869217   \n1    -0.842237 -1.020476     -0.438473   1.498210   -1.354131     0.869217   \n2    -0.842237  1.833666     -0.438473   1.498210   -1.354131     0.869217   \n3     1.187314  0.406595     -0.438473  -0.667463    1.177739     0.869217   \n4     1.187314 -0.544786     -0.438473  -0.667463   -0.228856    -1.150461   \n...        ...       ...           ...        ...         ...          ...   \n6494 -0.842237 -1.020476     -0.438473   1.498210   -1.354131     0.869217   \n6495  1.187314  0.406595     -0.438473  -0.667463    1.459058    -1.150461   \n6496  1.187314 -0.544786     -0.438473  -0.667463    1.459058    -1.150461   \n6497 -0.842237 -1.020476     -0.438473   1.498210   -1.354131     0.869217   \n6498 -0.842237  0.406595      2.280644  -0.667463   -0.791493    -1.150461   \n\n      stalk-root  stalk-surface-above-ring  stalk-surface-below-ring  \\\n0      -1.042574                  0.688059                 -0.887615   \n1      -1.042574                 -0.918730                  0.593034   \n2      -1.042574                  0.688059                  0.593034   \n3      -0.095455                  0.688059                  0.593034   \n4       0.851664                  0.688059                  0.593034   \n...          ...                       ...                       ...   \n6494   -1.042574                 -0.918730                  0.593034   \n6495   -1.042574                  0.688059                  0.593034   \n6496    2.745902                  0.688059                  2.073683   \n6497   -1.042574                  0.688059                  0.593034   \n6498   -1.042574                  0.688059                 -0.887615   \n\n      ring-type  spore-print-color  population   habitat  \n0     -1.261850           1.419717    0.287342 -0.877177  \n1     -1.261850           1.419717    0.287342  1.443749  \n2     -1.261850           1.419717    0.287342  0.283286  \n3      0.954123          -0.255816    0.287342 -0.877177  \n4      0.954123          -0.255816   -1.301290  0.863517  \n...         ...                ...         ...       ...  \n6494  -1.261850           1.419717    0.287342  1.443749  \n6495  -1.261850           1.419717   -2.095607  2.604212  \n6496   0.954123          -0.255816    1.081659  1.443749  \n6497  -1.261850           1.419717    0.287342  1.443749  \n6498   0.954123           1.419717   -1.301290 -0.296946  \n\n[6499 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bruises</th>\n      <th>odor</th>\n      <th>gill-spacing</th>\n      <th>gill-size</th>\n      <th>gill-color</th>\n      <th>stalk-shape</th>\n      <th>stalk-root</th>\n      <th>stalk-surface-above-ring</th>\n      <th>stalk-surface-below-ring</th>\n      <th>ring-type</th>\n      <th>spore-print-color</th>\n      <th>population</th>\n      <th>habitat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.842237</td>\n      <td>1.357976</td>\n      <td>-0.438473</td>\n      <td>1.498210</td>\n      <td>-1.354131</td>\n      <td>0.869217</td>\n      <td>-1.042574</td>\n      <td>0.688059</td>\n      <td>-0.887615</td>\n      <td>-1.261850</td>\n      <td>1.419717</td>\n      <td>0.287342</td>\n      <td>-0.877177</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.842237</td>\n      <td>-1.020476</td>\n      <td>-0.438473</td>\n      <td>1.498210</td>\n      <td>-1.354131</td>\n      <td>0.869217</td>\n      <td>-1.042574</td>\n      <td>-0.918730</td>\n      <td>0.593034</td>\n      <td>-1.261850</td>\n      <td>1.419717</td>\n      <td>0.287342</td>\n      <td>1.443749</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.842237</td>\n      <td>1.833666</td>\n      <td>-0.438473</td>\n      <td>1.498210</td>\n      <td>-1.354131</td>\n      <td>0.869217</td>\n      <td>-1.042574</td>\n      <td>0.688059</td>\n      <td>0.593034</td>\n      <td>-1.261850</td>\n      <td>1.419717</td>\n      <td>0.287342</td>\n      <td>0.283286</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.187314</td>\n      <td>0.406595</td>\n      <td>-0.438473</td>\n      <td>-0.667463</td>\n      <td>1.177739</td>\n      <td>0.869217</td>\n      <td>-0.095455</td>\n      <td>0.688059</td>\n      <td>0.593034</td>\n      <td>0.954123</td>\n      <td>-0.255816</td>\n      <td>0.287342</td>\n      <td>-0.877177</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.187314</td>\n      <td>-0.544786</td>\n      <td>-0.438473</td>\n      <td>-0.667463</td>\n      <td>-0.228856</td>\n      <td>-1.150461</td>\n      <td>0.851664</td>\n      <td>0.688059</td>\n      <td>0.593034</td>\n      <td>0.954123</td>\n      <td>-0.255816</td>\n      <td>-1.301290</td>\n      <td>0.863517</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6494</th>\n      <td>-0.842237</td>\n      <td>-1.020476</td>\n      <td>-0.438473</td>\n      <td>1.498210</td>\n      <td>-1.354131</td>\n      <td>0.869217</td>\n      <td>-1.042574</td>\n      <td>-0.918730</td>\n      <td>0.593034</td>\n      <td>-1.261850</td>\n      <td>1.419717</td>\n      <td>0.287342</td>\n      <td>1.443749</td>\n    </tr>\n    <tr>\n      <th>6495</th>\n      <td>1.187314</td>\n      <td>0.406595</td>\n      <td>-0.438473</td>\n      <td>-0.667463</td>\n      <td>1.459058</td>\n      <td>-1.150461</td>\n      <td>-1.042574</td>\n      <td>0.688059</td>\n      <td>0.593034</td>\n      <td>-1.261850</td>\n      <td>1.419717</td>\n      <td>-2.095607</td>\n      <td>2.604212</td>\n    </tr>\n    <tr>\n      <th>6496</th>\n      <td>1.187314</td>\n      <td>-0.544786</td>\n      <td>-0.438473</td>\n      <td>-0.667463</td>\n      <td>1.459058</td>\n      <td>-1.150461</td>\n      <td>2.745902</td>\n      <td>0.688059</td>\n      <td>2.073683</td>\n      <td>0.954123</td>\n      <td>-0.255816</td>\n      <td>1.081659</td>\n      <td>1.443749</td>\n    </tr>\n    <tr>\n      <th>6497</th>\n      <td>-0.842237</td>\n      <td>-1.020476</td>\n      <td>-0.438473</td>\n      <td>1.498210</td>\n      <td>-1.354131</td>\n      <td>0.869217</td>\n      <td>-1.042574</td>\n      <td>0.688059</td>\n      <td>0.593034</td>\n      <td>-1.261850</td>\n      <td>1.419717</td>\n      <td>0.287342</td>\n      <td>1.443749</td>\n    </tr>\n    <tr>\n      <th>6498</th>\n      <td>-0.842237</td>\n      <td>0.406595</td>\n      <td>2.280644</td>\n      <td>-0.667463</td>\n      <td>-0.791493</td>\n      <td>-1.150461</td>\n      <td>-1.042574</td>\n      <td>0.688059</td>\n      <td>-0.887615</td>\n      <td>0.954123</td>\n      <td>1.419717</td>\n      <td>-1.301290</td>\n      <td>-0.296946</td>\n    </tr>\n  </tbody>\n</table>\n<p>6499 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}